{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task C - Streaming Application\n",
    "\n",
    "This streaming application accepts data from all the 3 producers and based on various conditions are inserted in Mongo DB.\n",
    "--The conditions are as follows:\n",
    "\n",
    "   1. In one batch if the data is received from only Aqua and not Terra, and if the location of Aqua matches with the location of climate insert the data in Mongo DB following an embedded data model.\n",
    "   2. If data is received from only Terra and not Aqua, and if the location of Terra matches with the location of climate insert the data in Mongo DB following an embedded data model.\n",
    "   3. If data is received from both Terra and not Aqua, and if the location of Aqua and Terra both matches with the location of climate average the value of confidence and air_temperature and insert the data in Mongo DB following an embedded data model.\n",
    "   4. In any other case insert climate data into Mongo DB.\n",
    "    \n",
    "All the producers are given similar 'Topic' so that the information collected in this application is collected in one kafka stream. The data is then separated based on the sender ID of the data coming from different Producers. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-8_2.11:2.3.0 pyspark-shell'\n",
    "\n",
    "import geohash as g\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "from json import loads\n",
    "#import pygeohash as g\n",
    "from pymongo import MongoClient\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "\n",
    "def sendDataToDB(iter):\n",
    "    client = MongoClient()\n",
    "    db = client.fit5148_assignment_db #Creating database\n",
    "    collection = db.fit5148_Ass1 #Creating a collection\n",
    "    # The below 3 lists are created to collect data coming from different producers\n",
    "    climate=[]\n",
    "    aqua=[]\n",
    "    terra=[]\n",
    "    for record in iter:\n",
    "        data=json.loads(record[1])\n",
    "        if (data['sender_id']=='Climate'):           \n",
    "            data['hash']=g.encode(data['latitude'],data['longitude'],precision = 5) #Geohash code is generated\n",
    "            climate.append(data)            \n",
    "           # print(climate)\n",
    "        elif (data['sender_id']=='Aqua'):           \n",
    "            data['hash']=g.encode(data['latitude'],data['longitude'],precision = 5) #Geohash code is generated\n",
    "            aqua.append(data)            \n",
    "           # print(aqua)            \n",
    "        elif (data['sender_id']=='Terra'):           \n",
    "            data['hash']=g.encode(data['latitude'],data['longitude'],precision = 5) #Geohash code is generated\n",
    "            terra.append(data)\n",
    "            \n",
    "           # print('trip')\n",
    "        \n",
    "        \n",
    "        Aqua2=[]\n",
    "        Terra2=[]\n",
    "        Fire=[]\n",
    "        \n",
    "        if (len(aqua)!=0 and len(terra)!=0):\n",
    "            \n",
    "            for i in range(len(climate)):\n",
    "                climate[i]['Fire'] = []\n",
    "                if (climate[i]['hash']==aqua[0]['hash'] and climate[i]['hash']==terra[0]['hash']):\n",
    "                    fire = {}\n",
    "                    fire['surf_air_temp']=(aqua[0]['surf_air_temp'] + terra[0]['surf_air_temp'])/2\n",
    "                    #aqua[0]['surf_air_temp']=(aqua[0]['surf_air_temp'] + terra[0]['surf_air_temp'])/2\n",
    "                    #aqua[0]['confidence']= (aqua[0]['confidence'] + terra[0]['confidence'])/2\n",
    "                    fire['confidence']= (aqua[0]['confidence'] + terra[0]['confidence'])/2\n",
    "                    #Fire=Fire.append(aqua[0])           \n",
    "                    climate[i]['fire']= [fire]\n",
    "                    collection.insert(climate[i])\n",
    "                   # print('a n t')\n",
    "\n",
    "                elif (climate[i]['hash']==aqua[0]['hash'] and climate[i]['hash']!=terra[0]['hash']):\n",
    "                    fire = {}\n",
    "                    fire['surf_air_temp']=aqua[0]['surf_air_temp']\n",
    "                    fire['confidence']= aqua[0]['confidence']\n",
    "                    climate[i]['Fire']=[fire]\n",
    "                    collection.insert(climate[i])\n",
    "                   # print('a n c')\n",
    "\n",
    "                elif (climate[i]['hash']==terra[0]['hash'] and  climate[i]['hash']!= aqua[0]['hash']):\n",
    "                    \n",
    "                    fire = {}\n",
    "                    fire['surf_air_temp']=terra[0]['surf_air_temp']\n",
    "                    fire['confidence']= terra[0]['confidence']#Terra2=Terra2.append(terra[0])\n",
    "                    climate[i]['Fire']=[fire]\n",
    "                    collection.insert(climate[i])\n",
    "                    print('t n c')\n",
    "                \n",
    "        elif (len(aqua)>0 and len(terra)==0):\n",
    "            for i in range(len(climate)):\n",
    "                climate[i]['Fire'] = []\n",
    "                if (climate[i]['hash']==aqua[0]['hash']):\n",
    "                    #Aqua2=Aqua2.append(aqua[0])\n",
    "                    climate[i]['Fire']=[aqua[0]]\n",
    "                    collection.insert(climate[i])\n",
    "                   # print('a')\n",
    "\n",
    "                else:\n",
    "                    collection.insert(climate[i])\n",
    "            \n",
    "        elif (len(aqua)==0 and len(terra) >0): \n",
    "            for i in range(len(climate)):\n",
    "                climate[i]['Fire'] = []\n",
    "                if (climate[i]['hash']==terra[0]['hash']):\n",
    "                    #Terra2=Terra2.append(terra[0])\n",
    "                    climate[i]['Fire']=[terra[0]]\n",
    "                    collection.insert(climate[i]) \n",
    "                  #  print('t')\n",
    "\n",
    "                else:\n",
    "                    collection.insert(climate[i])  \n",
    "                    \n",
    "                    \n",
    "        else:\n",
    "            #db.collection.drop()\n",
    "            for i in range(len(climate)):\n",
    "                climate[i]['Fire'] = []\n",
    "                collection.insert(climate[i])    \n",
    "                    \n",
    "        try:\n",
    "          \n",
    "            print('trip')\n",
    "        except Exception as ex:\n",
    "            print(\"Exception Occured. Message: {0}\".format(str(ex)))\n",
    "            \n",
    "    client.close()\n",
    "\n",
    "n_secs = 10\n",
    "topic = \"S1\"\n",
    "\n",
    "conf = SparkConf().setAppName(\"KafkaStreamProcessor\").setMaster(\"local[2]\")\n",
    "sc = SparkContext.getOrCreate()\n",
    "if sc is None:\n",
    "    sc = SparkContext(conf=conf)\n",
    "sc.setLogLevel(\"WARN\")\n",
    "ssc = StreamingContext(sc, n_secs)\n",
    "    \n",
    "kafkaStream = KafkaUtils.createDirectStream(ssc, [topic], {\n",
    "                        'bootstrap.servers':'127.0.0.1:9092', \n",
    "                        'group.id':'week11-group', \n",
    "                        'fetch.message.max.bytes':'15728640',\n",
    "                        'auto.offset.reset':'largest'})\n",
    "                        # Group ID is completely arbitrary\n",
    "\n",
    "lines = kafkaStream.foreachRDD(lambda rdd: rdd.foreachPartition(sendDataToDB))\n",
    "\n",
    "ssc.start()\n",
    "time.sleep(600) # Run stream for 10 minutes just in case no detection of producer\n",
    "# ssc.awaitTermination()\n",
    "ssc.stop(stopSparkContext=True,stopGraceFully=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
